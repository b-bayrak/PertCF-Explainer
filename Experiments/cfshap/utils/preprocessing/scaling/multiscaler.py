"""
    This module implements the MultiScaler.
    The multi scaler is a scaler that allows for different scaling within the same class through an argument passed to the `transform` methods.
    e.g., STD, MAD, Quantile, etc.

"""

__all__ = [
    'MultiScaler',
    'IdentityScaler',
    'get_scaler_name',
    'SCALERS',
]
__author__ = 'Emanuele Albini'

from typing import Union

import numpy as np
import scipy as sp

from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.base import BaseEstimator, TransformerMixin

from ... import keydefaultdict

from .madscaler import (
    MedianAbsoluteDeviationScaler,
    MeanAbsoluteDeviationScaler,
    MeanAbsoluteDeviationFromMedianScaler,
    MedianAbsoluteDeviationFromMeanScaler,
)
from .quantiletransformer import EfficientQuantileTransformer

# NOTE: This will be deprecated, it is confusing
_DISTANCE_TO_SCALER = {
    'euclidean': 'std',
    'manhattan': 'mad',
    'cityblock': 'mad',
    'percshift': 'quantile',
}

_SCALER_TO_NAME = {
    'quantile': 'Quantile',
    'std': 'Standard',
    'mad': 'Median Absolute Dev. (from median)',
    'Mad': 'Mean Absolute Dev. (from mean)',
    'madM': 'Median Absolute Dev. from mean',
    'Madm': 'Mean Absolute Dev. from median',
    'minmax': 'Min Max',
    'quantile_nan': 'Quantile w/NaN OF',
    'quantile_sum': 'Quantile w/OF-Î£',
    None: 'Identity',
}

SCALERS = list(_SCALER_TO_NAME.keys())


def _get_method_safe(method):
    if method is None or method in SCALERS:
        return method
    # NOTE: This will be deprecated, it is confusing
    elif method in list(_DISTANCE_TO_SCALER.keys()):
        return _DISTANCE_TO_SCALER[method]
    else:
        raise ValueError('Invalid normalization method.')


def get_scaler_name(method):
    return _SCALER_TO_NAME[_get_method_safe(method)]


class IdentityScaler(TransformerMixin, BaseEstimator):
    """A dummy/identity scaler compatible with the sklearn interface for scalers
        It returns the same input it receives.

    """
    def __init__(self):
        pass

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        return X

    def inverse_transform(self, X):
        return X


def get_transformer_class(method):
    method = _get_method_safe(method)

    if method is None:
        return IdentityScaler
    elif method == 'std':
        return StandardScaler
    elif method == 'minmax':
        return MinMaxScaler
    elif method == 'mad':
        return MedianAbsoluteDeviationScaler
    elif method == 'Mad':
        return MeanAbsoluteDeviationScaler
    elif method == 'Madm':
        return MeanAbsoluteDeviationFromMedianScaler
    elif method == 'madM':
        return MedianAbsoluteDeviationFromMeanScaler
    elif method == 'quantile':
        return EfficientQuantileTransformer  # PercentileShifterCached
    elif method == 'quantile_nan':
        return EfficientQuantileTransformer
    elif method == 'quantile_sum':
        return EfficientQuantileTransformer


def get_transformer_kwargs(method):
    method = _get_method_safe(method)

    if method == 'quantile_nan':
        return dict(overflow="nan")
    elif method == 'quantile_sum':
        return dict(overflow="sum")
    else:
        return dict()


class MultiScaler:
    """Multi-Scaler

    Raises:
        Exception: If an invalid normalization is used

    """
    # Backward compatibility
    NORMALIZATION = SCALERS

    def __init__(self, data: np.ndarray = None):
        """Constructor

            - The data on which to train the scalers can be passed here (in the constructor), or
            - It can also be passe later using the .fit(data) method.

        Args:
            data (pd.DataFrame): A dataframe with the features, optional. Default to None.

        """

        if data is not None:
            return self.fit(data)

        self.__suppress_warning = False

    def fit(self, data: np.ndarray):
        self.data = np.asarray(data)

        self.transformers = keydefaultdict(lambda method: get_transformer_class(method)
                                           (**get_transformer_kwargs(method)).fit(self.data))

        def single_transformer(method, f):
            return get_transformer_class(method)(**get_transformer_kwargs(method)).fit(self.data[:, f].reshape(-1, 1))

        self.single_transformers = keydefaultdict(lambda args: single_transformer(*args))
        self.data_transformed = keydefaultdict(lambda method: self.transform(self.data, method))

        self.covs = keydefaultdict(lambda method, lib: self.__compute_covariance_matrix(self.data, method, lib))

        self._lower_bounds = keydefaultdict(lambda method: self.data_transformed[method].min(axis=0))
        self._upper_bounds = keydefaultdict(lambda method: self.data_transformed[method].max(axis=0))

    def lower_bounds(self, method):
        return self._lower_bounds[method]

    def upper_bounds(self, method):
        return self._upper_bound[method]

    def suppress_warnings(self, value=True):
        self.__suppress_warning = value

    def __compute_covariance_matrix(self, data, method, lib):
        if lib == 'np':
            return sp.linalg.inv(np.cov((self.transform(data, method=method)), rowvar=False))
        elif lib == 'tf':
            from ..tf import inv_cov as tf_inv_cov
            return tf_inv_cov(self.transform(data, method=method))
        else:
            raise ValueError('Invalid lib.')

    def transform(self, data: np.ndarray, method: str, **kwargs):
        """Normalize the data according to the "method" passed

        Args:
            data (np.ndarray): The data to be normalized (nb_samples x nb_features)
            method (str, optional): Normalization (see class documentation for details on the available scalings). Defaults to 'std'.

        Raises:
            ValueError: Invalid normalization

        Returns:
            np.ndarray: Normalized array
        """
        method = _get_method_safe(method)
        return self.transformers[method].transform(data)

    def inverse_transform(self, data: np.ndarray, method: str = 'std'):
        """Un-normalize the data according to the "method" passes

        Args:
            data (np.ndarray): The data to be un-normalized (nb_samples x nb_features)
            method (str, optional): Normalization (see class documentation for details on the available scalings). Defaults to 'std'.

        Raises:
            ValueError: Invalid normalization

        Returns:
            np.ndarray: Un-normalized array
        """
        method = _get_method_safe(method)
        return self.transformers[method].inverse_transform(data)

    def feature_deviation(self, method: str = 'std', phi: Union[float, int] = 1):
        """Get the deviation of each feature according to the normalization method

        Args:
            method (str): method (str, optional): Normalization (see class documentation for details on the available scalings). Defaults to 'std'.
            phi (Union[float, int]): The fraction of the STD/MAD/MINMAX. Default to 1.

        Raises:
            ValueError: Invalid normalization

        Returns:
            np.ndarray: Deviations, shape = (nb_features, )
        """
        method = _get_method_safe(method)
        transformer = self.transformers[method]
        if 'scale_' in dir(transformer):
            return transformer.scale_ * phi
        else:
            return np.ones(self.data.shape[1]) * phi

    def feature_transform(self, x: np.ndarray, f: int, method: str):
        x = np.asarray(x)
        transformer = self.get_feature_transformer(method, f)
        return transformer.transform(x.reshape(-1, 1))[:, 0]

    def value_transform(self, x: float, f: int, method: str):
        x = np.asarray([x])
        transformer = self.get_feature_transformer(method, f)
        return transformer.transform(x.reshape(-1, 1))[:, 0][0]

    def shift_transform(self, X, shifts, method, **kwargs):
        transformer = self.get_transformer(method)
        if 'shift' in dir(transformer):
            return transformer.shift_transform(X, shifts=shifts, **kwargs)
        else:
            return X + shifts

    def move_transform(self, X, costs, method, **kwargs):
        transformer = self.get_transformer(method)
        assert costs.shape[0] == X.shape[1]
        return transformer.inverse_transform(transformer.transform(X) + np.tile(costs, (X.shape[0], 1)))

    def get_transformer(self, method: str):
        return self.transformers[_get_method_safe(method)]

    def get_feature_transformer(self, method: str, f: int):
        return self.single_transformers[(_get_method_safe(method), f)]

    def single_transform(self, x, *args, **kwargs):
        return self.transform(np.array([x]), *args, **kwargs)[0]

    def single_inverse_transform(self, x, *args, **kwargs):
        return self.inverse_transform(np.array([x]), *args, **kwargs)[0]

    def single_shift_transform(self, x, shift, **kwargs):
        return self.shift_transform(np.array([x]), np.array([shift]), **kwargs)[0]

    # NOTE: This must be deprecated, it does not fit here.
    def covariance_matrix(self, data: np.ndarray, method: Union[None, str], lib='np'):
        if data is None:
            return self.covs[(method, lib)]
        else:
            return self.__compute_covariance_matrix(data, method, lib)

    # NOTE: This must be deprecated, it does not fit here.
    def covariance_matrices(self, data: np.ndarray, methods=None, lib='np'):
        """Compute the covariance matrices

        Args:
            data (np.ndarray): The data from which to extract the covariance

        Returns:
            Dict[np.ndarray]: Dictionary (for each normalization method) of covariance matrices
        """
        # If no method is passed we compute for all of them
        if methods is None:
            methods = self.NORMALIZATION

        return {method: self.covariance_matrix(data, method, lib) for method in methods}